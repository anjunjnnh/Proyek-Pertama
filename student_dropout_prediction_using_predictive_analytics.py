# -*- coding: utf-8 -*-
"""Student Dropout Prediction Using Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OK3lXUqYLJLO2BV113Omp-uGwB6p22OY

# **Student Dropout Prediction Using Predictive Analytics**

---

oleh : Anju Anjannah

## **Deskripsi Proyek**
Proyek ini bertujuan untuk mengembangkan model machine learning yang dapat memprediksi status dropout mahasiswa dengan lebih akurat dan efisien. Tingginya angka dropout mahasiswa merupakan permasalahan signifikan di institusi pendidikan. Proses identifikasi mahasiswa yang berisiko dropout secara manual seringkali sulit, memakan waktu, dan tidak akurat, yang dapat menyebabkan terlambatnya intervensi dan dukungan yang dibutuhkan mahasiswa. Hal ini dapat berdampak negatif pada mahasiswa itu sendiri maupun performa institusi. Model prediksi dropout mahasiswa dapat membantu mengatasi permasalahan ini dengan memberikan solusi yang lebih akurat, efisien, dan berbasis data, memungkinkan institusi untuk mengidentifikasi dan memberikan dukungan tepat waktu kepada mahasiswa yang membutuhkan.

# **1. Import Libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression,Perceptron
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay

"""# **2. Data Understanding**

**2.1 Data loading**

Sumber Dataset : https://www.kaggle.com/datasets/adilshamim8/predict-students-dropout-and-academic-success/code
"""

from google.colab import files
uploaded = files.upload()

filename = list(uploaded.keys())[0]
data = pd.read_csv(filename)

data

"""**2.2 EDA**"""

data.info()

data.isnull().sum()

data.describe().T

data['target'].value_counts()

data['target'] = LabelEncoder().fit_transform(data['target'])

data['target'].value_counts()

plt.figure(figsize=(5, 10))
sns.histplot(data['target'], color="Blue", kde=True)
plt.show()

plt.figure(figsize=(5, 10))
sns.countplot(data = data, x="target").set_title('Target Distribution')
plt.show()

plt.figure(figsize=(8, 8))
plt.title("Education Status")
plt.pie(data['target'].value_counts(), labels = ['Graduate', 'Dropout', 'Enrolled'], explode = (0.0, 0.0, 0.0), autopct='%1.2f%%', shadow = True)
plt.legend( loc = 'lower right')
plt.show()

plt.figure(figsize=(8, 8))
plt.title("Gender")
plt.pie(data['Gender'].value_counts(), labels = ['Male', 'Female'], explode = (0.1, 0.0), autopct='%1.2f%%', shadow = True)
plt.legend( loc = 'lower right')
plt.show()

plt.figure(figsize=(20, 45))

for i in range(0, 35):
    plt.subplot(12, 3, i+1)
    sns.histplot(data.iloc[:, i], color='blue', kde=True)
    plt.title(data.columns[i])
    plt.grid()

plt.tight_layout()
plt.show()

#feature selection
corr_matrix = data.corr(method="pearson")
plt.figure(figsize=(10, 10))
sns.heatmap(corr_matrix, vmin=-1., vmax=1., annot=False, fmt='.2f', cmap="YlGnBu", cbar=True, linewidths=0.5)
plt.title("Feature Correlation Matrix")
plt.show()

["Tuition fees up to date","Curricular units 1st sem (approved)","Curricular units 1st sem (grade)","Curricular units 2nd sem (approved)","Curricular units 2nd sem (grade)"]
corr_matrix["target"]

"""**Insight : <br>**

Tahap ini berfokus pada pemahaman mendalam terhadap dataset. Ini melibatkan pemuatan data dari sumber eksternal, pemeriksaan informasi dasar data (tipe data, nilai non-null) menggunakan `.info()`, identifikasi jumlah nilai yang hilang menggunakan `.isnull().sum()`, serta analisis statistik deskriptif menggunakan `.describe().T` untuk memahami distribusi fitur numerik.

Selain itu, dilakukan Eksplorasi Data (EDA) untuk memvisualisasikan distribusi variabel target dan fitur-fitur penting lainnya menggunakan histogram, countplot, dan pie chart. Analisis korelasi menggunakan heatmap juga dilakukan untuk mengidentifikasi hubungan antar fitur dan antara fitur dengan variabel target. Temuan dari tahap ini memberikan gambaran awal tentang struktur data, kualitas data, distribusi variabel, dan potensi fitur yang relevan untuk prediksi. **Catatan**: Ditemukan distribusi variabel target yang tidak seimbang dan beberapa fitur yang memiliki korelasi dengan target.

# **3. Data Preparation**

**3.1 Data Cleaning**
"""

data.drop(data[data['target'] == 1].index, inplace = True)
data

data['Dropout'] = data['target'].apply(lambda x: 1 if x==0 else 0)
data

plt.figure(figsize=(5, 10))
sns.histplot(data['Dropout'], color="red", kde=True) # Use histplot and add kde=True for a kernel density estimate line
plt.show()

plt.figure(figsize=(8, 8))
plt.title("Dropout Status")
plt.pie(data['Dropout'].value_counts(),  labels = ['Non-Dropout', 'Dropout'], explode = (0.1, 0.0), autopct='%1.2f%%', shadow = False)
plt.legend( loc = 'lower right')
plt.show()

"""**3.2 Standarisasi**"""

x = data.iloc[:, :36].values
#x = df[["Tuition fees up to date","Curricular units 1st sem (approved)","Curricular units 1st sem (grade)","Curricular units 2nd sem (approved)","Curricular units 2nd sem (grade)"]].values
print(x)
x = StandardScaler().fit_transform(x)
x

y = data['Dropout'].values
y

"""**3.3 Split Data**"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)

"""**Insight :** <br>

Tahap ini mempersiapkan data untuk pembangunan model machine learning. Ini meliputi pembersihan data dengan menghapus baris yang tidak relevan dengan masalah klasifikasi biner (yaitu menghapus status 'Masih Studi'), membuat variabel target biner baru ('Dropout'), standarisasi fitur numerik menggunakan `StandardScaler` untuk membawa fitur-fitur ke skala yang serupa (penting untuk beberapa algoritma), dan membagi data menjadi set pelatihan dan pengujian. Pembagian data ini memastikan bahwa model dievaluasi pada data yang belum pernah dilihat selama pelatihan.

# **4. Model Development dan Evaluation**
"""

def perform(y_pred):
    print("Precision : ", precision_score(y_test, y_pred, average = 'micro'))
    print("Recall : ", recall_score(y_test, y_pred, average = 'micro'))
    print("Accuracy : ", accuracy_score(y_test, y_pred))
    print("F1 Score : ", f1_score(y_test, y_pred, average = 'micro'))
    cm = confusion_matrix(y_test, y_pred)
    print("\n", cm)
    print("\n")
    print("**"*27 + "\n" + " "* 16 + "Classification Report\n" + "**"*27)
    print(classification_report(y_test, y_pred))
    print("**"*27+"\n")

    cm = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=['Non-Dropout', 'Dropout'])
    cm.plot()

"""a. Gaussian Naive Bayes"""

model1_nb = GaussianNB()
model1_nb.fit(x_train, y_train)

y_pred_model1 = model1_nb.predict(x_test)

perform(y_pred_model1)

"""b. Logistic Regression"""

model2_lr = LogisticRegression()
model2_lr.fit(x_train, y_train)

y_pred_model2 = model2_lr.predict(x_test)

perform(y_pred_model2)

"""c. Random Forest Classifier"""

model3_rf = RandomForestClassifier(n_estimators=500,criterion='entropy')
model3_rf.fit(x_train, y_train)

y_pred_model3 = model3_rf.predict(x_test)

perform(y_pred_model3)

"""**Insight :** <br>

Pada tahap ini, tiga model klasifikasi machine learning dibangun dan dievaluasi: Gaussian Naive Bayes, Logistic Regression, dan Random Forest Classifier. Setiap model dilatih pada set data pelatihan dan kemudian digunakan untuk membuat prediksi pada set data pengujian.

Untuk mengevaluasi kinerja setiap model, digunakan fungsi `perform` yang menghitung dan menampilkan metrik evaluasi umum seperti Precision, Recall, Accuracy, F1 Score, Confusion Matrix, dan Classification Report. Metrik-metrik ini memberikan pandangan komprehensif tentang seberapa baik setiap model memprediksi status putus studi. **Temuan utama** dari tahap ini adalah metrik kinerja individual untuk setiap model.

# **5. Comparison of Results**
"""

predict=[y_pred_model1,y_pred_model2,y_pred_model3]
acc=[]
classifiers=["NaiveBayes","Logistic Regression","RandomForest"]
for i in predict:
    temp=accuracy_score(y_test, i)
    acc.append(temp)

# Temukan indeks akurasi terbaik
best_acc_index = np.argmax(acc)

# Buat daftar warna
colors = ['blue'] * len(classifiers)
colors[best_acc_index] = 'red'
plt.barh(classifiers, acc, color=colors)

# Add labels and title
plt.ylabel('Classifiers')
plt.xlabel('Accuracy')
plt.title('Perbandingan Accuracy Model')
plt.show()

"""**Insight :** <br>

Tahap terakhir ini membandingkan kinerja ketiga model yang telah dilatih berdasarkan metrik akurasi. Hasil akurasi dari setiap model dikumpulkan dan divisualisasikan menggunakan plot bar horizontal. Plot ini memudahkan perbandingan visual dan identifikasi model dengan kinerja terbaik (ditunjukkan dengan bar berwarna merah). Hasil akhir menunjukkan model **Random Forest Classifier** yang mencapai akurasi tertinggi dalam memprediksi putus studi pada set data pengujian.
"""